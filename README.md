# Syllabus

# Schedule

| Class        | Topics           | Before | After/during | Assignments  | Lab
| -------------:|:-------------:|:-------:|:-----:|:-------------:|:------:|
| W1C1 | Introduction, Slack and Snap! | | watch Welcome to BJC, Key to Success in BJC, Program or Be Programmed, Snap Lab1 videos ; read Introduction to Abstraction + following quiz! | | Lab 1.1 - finish at home |
| W1RS | see below |
| W1C2 | Abstraction | all abstraction videos | | | Help with Lab 1.1, Lab 1.2 |
| W2C1 | Functions | all functions videos | read Blown to bits chapter 1 + quiz! | | Labs 1.3 and 1.5 + 1 project |
| W2RS | see below |
| W2C2 | More abstractions | all abstraction revisited videos | finish quizzes for labs | | Labs 2.1 and 2.2 |
| W3C1 | Creativity | all creativity videos | Blown to bits chapter 2 + 2 quizzes! | | lab 2.3, 2.4 + one project |
| W3RS | see below |
| W3C2 | Programming paradigms | all programming paradigms videos and quizzes | | HW1 | Labs 2.1 and 2.2 |
| W4C1 | Algorithms 1 | All videos | B2b chapter 4 | | Labs 3.1 and 3.2|
| W4RS | see below |
| W4C2 | Algorithms 2 | All videos | | | Labs 5.1 and 5.2|
| W5C1 | Internet 1 | All videos | B2b chapter 5 and conclusion | | Labs 4.1 and 4.2|
| W5RS | see below |
| W5C2 | Internet 2 | All videos | | | Labs 4.3, 4.4 and 4.5|
| W6C1 | Global impacts of computing | All videos | B2b appendix | HW2 | Midterm project|
| W6RS | see below |
| W6C2 | Midterm exam |

| W7C1 | Data | All videos | Data and algorithmic complexity articles | | Labs 3.4 and 3.5 |
| W7RS | see below |
| W7C2 | Algorithmic complexity  | all videos | | | Labs 5.3 and 5.4 |
| W8C1 | Global impact 2 | All videos | all stories in these two classes | | Lab 6.1 |
| W8RS | see below |
| W8C2 | Global impact 3 | all videos | | | Lab 6.2 |
| W9C1 | Saving the world with computing | All videos | all stories | | Lab 6.3 and a project |
| W9RS | see below |
| W9C2 | ? |
| W10C1 | Recursion 1 | All videos | all stories of the two classes | | Labs 7.1and 7.2 |
| W10RS | see below |
| W10C2 | Recursion 2 | All videos |  | | Labs 8.1 and 8.2 |
| W10C2 | ? |

## W1RS

1. To explain Abstraction, Professor Harvey used the automobile as an
example, with its many layers of complexity, and the "two pedals, one
steering wheel" interface that has stood the test of time. Imagine you
were teaching abstraction to a ten-year-old. Describe another
non-computing innovation, its abstraction layers, and at least one of
its interfaces (indicate whether it has changed over time or not).
2. Abstraction allows us to focus on the important aspects of something and
put the details aside for later. Describe a process where you utilize
abstraction: what parts are the high-level ideas and what parts are the
low-level details you "abstract away"? What is the the crossover point
where you stop talking about the abstract concepts and get around to
talking about the details?
3. Are there ever situations where we don't use Abstraction? Where are the
details that are so important that we cannot afford to miss them or hide
them?

## W2RS

1. Was there anything you disagreed with, or thought was overstated?
2. Which Koan was the most enlightening (i.e., taught you the most) and
what did you believe before reading it?
3. The book was written in 2008; what feels the most dated? Said another
way, was there anything that has happened since then that you would make
sure to put in Chapter 1 if the book were rewritten today?

## W3RS

1. The authors argue we gave away our privacy to save time, money,
convenience, exhibitionism, or "because you can't live any other way".
Are there times when you do not give in to the trade-off? Why? (e.g.,
you do not sign up for reward cards because you do not want supermarkets
knowing what you buy, you pay cash because you do not want credit card
companies to track you, etc.)
2. In terms of internet exposure, where do you fall on the scale of 1-10
(where 1 might be an Amish family with no electricity, and 10 might be
Jennifer Kay Ringley who used her "Jennicam" to document everything
about her life for 7 years.) and why? E.g., Do you have a website? Write
a blog? Post photos and videos of yourself to social media?
3. What would your reaction be if people in your neighborhood started using
devices (for their own interest) that could affect your personal
privacy? (e.g., flying drones overhead, wearing "Google Glass"-like
eyeglasses, installing security cameras outside their house / apartment,
etc.) Would you speak up?4
4. In the United States, legislators have toyed with requiring always-on
body cameras on police officers in the United States. What are some of
the key benefits and shortcomings of that proposal?
5. The second half of the reading talks about various attempts to erudite
leaders to define what privacy is and what rights the individual should
have. If you were to concisely articulate what rights every person on
earth should have with regard to privacy, what would it be? (Consider
elements like "the right to know WHO has your information", "the right
to BAN a group from collecting information about you", "the right to
CORRECT the information they have about you", "the right to be FORGOTTEN
(i.e., for all the people who have information about me, delete ALL of
it)", etc.)
6. Now consider the opposite side of the coin. Do governments, society, or
institutions have any rights to have your information? (i.e., Would it
really make sense to be able to tell your National Security
Administration [aka Ministry of Defense and Intelligence, etc.] that
they can't know about you? That said, don't the same "surveillance"
mechanisms that can prevent terrorism allow a state to silence all
dissent? Where's the line?)

## W4RS

1. What do you think about the idea that search engine caches are partly to
"blame" for the loss of our privacy? That is, any information about you
available on the web (even for an instant) can get captured by any one
of the millions of roving spiders, and archived for eternity. The EU has
a "right to be forgotten" law that exists for exactly that reason, to
force search engines to remove traces of your digital footprint (we'll
see more of that in a few weeks) from its caches.
2. Given how much "power" search engines now have, do you think they should
be regulated by some agency? Argue your case. Recall how Google "stung"
BMW for what they perceived to be an attempt to "rig" the search
results. What prevents a search engine site from doing that to any
company or group they don't like? "Who watches the search engines?"
3. You're a search engine provider. A country comes to you, whose income
is mostly funded by the sale of tobacco, and wants their people to
believe that tobacco products are extremely healthy and invigorating.
They want all searches of tobacco in their country to return listings
that support their false claims. What is the right call (i.e., comply
with local laws (as Google finally did with China) or refuse to alter
your automatically-generated searches and rankings)? Argue your point.
Where should a company draw the line, if ever?
4. Again, you're a search engine provider. A brutally repressive country
wants to know all the users who searched for terms that refer to
terrorist acts against their country. Perhaps that's reasonable in the
name of national security. What if they then can ask for the users who
simply speak poorly of their leader? Or of all the people whose search
terms might indicate they belong to a minority ethnic or religious
group? Or of all the people who are advocating that women should have an
equal right to education (e.g., Malala Yousafzai)? What should your
policy be around what search data is released and to whom?

## W5RS

1. There's a section heading entitled "Having a Good System Doesn't Mean
People Will Use It", and it talks about the challenge to get the masses
to use encryption on a regular basis. We all use it for our Internet
commerce, because it's built in to the web browsers (ever notice the
lock symbol to the left of the "https" window above when you're doing
online shopping?). Would you advocate that all email systems incorporate
encryption to be on "by default", even if it meant that the email of
"dumb bad guys" (who weren't encrypting their email) was harder to
monitor? (I.e., do the benefits outweigh the problems?)
2. Blown to Bits says:
The risks of insecure encryption today arise from three forces acting in
consort: the high speed at which news of insecurities travels among
experts, the slow speed at which the inexpert recognize their
vulnerabilities, and the massive scale at which cryptographic software
is deployed.
Of the three "forces" that are continually preventing everyone from
having the most updated encryption software, which is the dominant
reason? What can we as a society do to address it?
3. The last two sentences in Blown to Bits are: “The legal and economic
   (and technical -Dan) decisions being made today, not just about bits
but about everything that depends on bits, will determine how our
descendants will lead their lives. The way the bits illuminate or
distort the world will shape the future of humanity.”. Are you
optimistic or pessimistic about the way things will play out, for
families, friends and society? Will cybercriminals become more
dangerous, our physical and digital mistakes captured more frequently
and instantly shared with a billion people and archived forever, and our
personal freedoms continued to be stripped away so that free speech and
thought will be a thing of the past? Or will it give “the good guys”
even more tools to fight crime, help root out government oppression and
police brutality (via cell phones and body cameras), and give voice to
the unheard, views to the unseen, and representation to the
underrepresented.
4. Andrew Blum talks about wanting to peek below the abstraction of the
“cloud” and “Internet” to its physical underpinnings. He discovers it’s
just copper, fiber, insulation, and a whole lot of people, machinery,
buildings, boats and ocean floor. The people involved are engineers,
ship captains, divers, “jewelers”, and local laborers. What was the most
surprising thing you learned from the video?

## W6RS

1. Where do you fall on the Net Neutrality debate (for or against) and why?
One of the engineering triumphs of the architectural design of the
2. Internet is that "the Internet of yesterday did not focus on the today
of yesterday". Name another system (that has survived the test of time
and societal / technological transformations in ways the designers
couldn't have imagined) and describe what aspects of its design made it
so able to age gracefully.

## W7RS

1. The "Web 2.0 Summit" talked about how data (here, mostly social data) was
revolutionizing the music and television industry. What other industry
do you think is being revolutionized by data, and why?
2. In your own life, have you ever fallen into one of the ten data analysis
pitfalls? What were you working on, and which one was it?
3. What was the most surprising thing you learned from the visualizations
presented by Hans Rosling in his TED talk?
4. One of the powerful ideas in the article, as you'll see in this week's
videos as well, is that NP-complete problems are very special. If you
solve one, you solve them all (and in fact all problems in NP as well).
Are there other situations you've ever seen with this kind of tight
interdependence, i.e., if one falls, the others fall too? Here are some
examples: if the roof leaks in any of the houses in a new huge
development of thousands of houses, there's high probability that they
all will soon have leaks too. Inventing a way to recycle envelopes can
also help with recycling cardboard, card stock, mixed paper, etc. If one
zombie finds a way into your house during the Zombie Apocalypse, all the
others zombies can climb through that hole and get in too. That kind of
thing.
6. What was the most illuminating, or surprising thing you learned from the
article?

## W8RS

1. In the movie The Imitation Game, there was a very tense dramatic moment
when the British team had just proved they could crack the “unbreakable”
Enigma encryptions with the Bombe but immediately realized they couldn’t
let the Germans know. Their logic was that if the Germans knew their
messages had been compromised, they would change the way they encrypted
them, sending Turing’s team back to the drawing board. (This Wikipedia
article on the Cryptoanalysis of the EnigmaOpens in new window indicates
that the Germans did not know, for the most part, that their messages
were being seen: ) The Allies had to pick and choose when they would use
the decrypted information and act on it (offensively or defensively) so
as not to give away their hand. In the movie, it meant that they
couldn’t stop an attack that was going to kill one of the relatives of
one of the scientists. It must have been heartbreaking to have to accept
losses from secret attacks that could be prevented. The question is: Are
there other situations where you’ve seen heart-wrenching tradeoffs like
that? How do they handle it? How would YOU have handled a situation like
that?
2. In World War II, special-purpose computers were used for ballistics
calculations and decoding messages. Later computers were used as part of
Nuclear Attack Warning Systems, for weapon simulations, and to support
unmanned weapons (e.g., Drones). More recently, they have been used for
cyber-attacks (breaking into critical government and corporate systems)
and cyber-defense (to prevent such attacks). What do you think the near
future holds for computers and warfare? Will we see Terminator-style
autonomous killing machines? (Note that many Artificial Intelligence
researchers recently signed an open letter on autonomous weaponsOpens in
new window promising not to go down that path.) Or will it be fought
virtually, with fewer human lives lost, but more cyber-attacks that (for
example) take down national grids? Or something else altogether?
3. Juan Enriquez, in "Your Online Life, Permanent as a Tattoo", argues
   that your digital footprint is as permanent as a tattoo, and even
more so, because it will probably outlive you. He worries about a world
where people will link your photo to your desires and creepily offer you
a black dress in a store (having found out covertly you liked them based
on your face and their ability to link to that your social profile). He
predicts we'll spend our lives pursuing a "clean" reputation like
Sisyphus, warns us not to look into our friends' and family's past like
Orpheus, suggests that we stop fiddling with trivial social media
triflings like Atalanta, and not fall too much in love with ourselves
like Narcissus. Which of the predictions / warnings speaks the most to
you, that you agree with the most? That is, which of the suggestions
would you share first with a younger cousin coming online to social
media for the first time?
4. Alessandro Acquisti, in his "What Will A Future Without Secrets Look
Like?", paints quite a dystopian picture of the future if we do nothing
and continue on our current path. Augmented Reality devices (like Google
Glass) will allow people to instantly grab very private (e.g., social
security numbers) information from you using just a quick glimpse of you
from their always-on cameras. Employers will prejudge applicants
abilities based on their personal life (that is a little bit too
public). Marketers will be more effective at selling you things by
having virtual models whose faces are taken from composites of your
friends shown in personalized ads. People who normally would care about
revealing private information can be made not to care by distracting
them for fifteen seconds. He suggests a call to action to take back our
privacy by shaking us awake, recommending we use encryption software,
and fight to control our personal information. Is his argument
convincing? If you're sold, which of the dystopian futures or logical
points was the most surprising, or spoke the most to you? If you're
still doubtful, and aren't willing to pay the cost (e.g., advocacy, time
to install and use encryption software) for your privacy, what would it
take to convince you to act, and be less apathetic?

## W9RS

1. Samy Kamkar highlights three ways the Internet is vulnerable. Which do
you think is the most vulnerable and/or would cause the most
catastrophic damage if attacked, why do you feel that way, and how would
you defend it?
2. How do you feel about the advancements in Artificial Intelligence that
are allowing computers to continue to be better than humans in so many
activities? Do you believe (as many do) that machines will eventually
challenge us (and in the worst case, take over), or will they hit an
upper-limit and never develop to that point?

## W10RS

1. Self-driving cars open up an incredible ethical can of worms,
   legally. When an accident occurs (as it did here), who should bear
the legal risk -- the hardware manufacturer, software manufacturer,
software architect, or owner of the vehicle?
Assuming these cars would be the same cost as conventional cars, where
do you fall on the adoption scale for this technology, and why? Are you
so enthusiastic about this technology that you'd be waiting outside
2. Google offices overnight to be the first on your block to have one? Or
are you someone who loves driving so much (and/or doesn't want any part
of this whole "trust your life to algorithms") that you'd never get one?
3. We saw a car in the video "take advantage" of the "kindness of
self-driving cars" (ala Gone with the Wind) by cutting right in the
middle of a pair of them. What other potential problems do you see
(vandalism, grand theft auto, drivers taking advantage, taxi drivers out
of work, etc.) once our streets are filled with fully autonomous
self-driving cars and taxis, say with no steering wheel at all?
4. Opponents of game solving have likened it to the cutting down of
   trees in the Amazon. They feel it's a terrible thing for mankind to
do, an act that disturbs the pristine law of nature in some sense, and
removes the mystery from the games. Proponents speak of the possibility
for these systems to teach players how to play better, and be able to
watch two humans play and share with them a post-game analysis of all
the mistakes that were made. How do you feel about it?
5. Go was always thought of as a game that machines would never be able to
play at championship level, given how big it is and how hard it is to
capture the "intuition" that top players leverage when playing it. It
seems that is being proved wrong. What human activity will replace Go as
one of the hardest things for computers to do?
